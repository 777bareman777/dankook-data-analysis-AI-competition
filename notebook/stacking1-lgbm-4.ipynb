{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"stacking1-lgbm-4.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SS0O0XJPSgK9","executionInfo":{"status":"ok","timestamp":1601814495458,"user_tz":-540,"elapsed":1078,"user":{"displayName":"bare","photoUrl":"","userId":"10819893525008163668"}},"outputId":"ccc82b49-9a00-42dc-e33d-803f39bbda30","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!git clone https://github.com/Microsoft/LightGBM \\\n","&& cd LightGBM \\\n","&& mkdir build \\\n","&& cmake -DUSE_GPU=1 \\\n","&& make -j$(nproc) \\\n","&& sudo apt-get -y install python-pip \\\n","&& sudo -H pip install setuptools pandas numpy scipy scikit-learn -U \\\n","&& cd /content/LightGBM/python-package \\\n","&& sudo python setup.py install \\"],"execution_count":1,"outputs":[{"output_type":"stream","text":["fatal: destination path 'LightGBM' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qYWU3VILfKgO","executionInfo":{"status":"ok","timestamp":1601814495459,"user_tz":-540,"elapsed":1068,"user":{"displayName":"bare","photoUrl":"","userId":"10819893525008163668"}}},"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-Yt05wlf57T","executionInfo":{"status":"ok","timestamp":1601814495939,"user_tz":-540,"elapsed":1540,"user":{"displayName":"bare","photoUrl":"","userId":"10819893525008163668"}}},"source":["import numpy as np\n","import pandas as pd\n","\n","from tqdm import tqdm\n","\n","import warnings\n","from pathlib import Path\n","\n","from sklearn.metrics import log_loss\n","from sklearn.model_selection import StratifiedKFold\n","\n","import lightgbm as lgbm\n","\n","from scipy.optimize import minimize"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"0c5Hugt8f5FM","executionInfo":{"status":"ok","timestamp":1601814495940,"user_tz":-540,"elapsed":1533,"user":{"displayName":"bare","photoUrl":"","userId":"10819893525008163668"}}},"source":["pd.set_option('max_columns', 100)\n","pd.set_option('display.precision', 4)\n","\n","warnings.filterwarnings('ignore')"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DgF5VBQNf5Hg"},"source":["# 데이터 로드"]},{"cell_type":"code","metadata":{"id":"vlSuesYQf5Jk","executionInfo":{"status":"ok","timestamp":1601814495940,"user_tz":-540,"elapsed":1525,"user":{"displayName":"bare","photoUrl":"","userId":"10819893525008163668"}}},"source":["# 로컬 버전\n","\n","# data_dir = Path('../input/dankook')\n","# feature_dir = Path('../output/feature')\n","# val_dir = Path('../output/oof_pred')\n","# test_dir = Path('../output/test_pred')\n","# sub_dir = Path('../output/sub')\n","\n","\n","# train_file = data_dir / 'train.csv'\n","# test_file = data_dir / 'test.csv'\n","# sample_file = data_dir / 'sample_submission.csv'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"XpdYI7Hif5MN","executionInfo":{"status":"ok","timestamp":1601814495941,"user_tz":-540,"elapsed":1516,"user":{"displayName":"bare","photoUrl":"","userId":"10819893525008163668"}},"outputId":"daf127c4-a401-4b7a-8c2d-7520ac7a67f8","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# 코렙 \n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","data_dir = Path('/content/drive/My Drive/Colab Notebooks/input/dankook')\n","feature_dir = Path('/content/drive/My Drive/Colab Notebooks/output/feature')\n","val_dir = Path('/content/drive/My Drive/Colab Notebooks/output/oof_pred')\n","test_dir = Path('/content/drive/My Drive/Colab Notebooks/output/test_pred')\n","sub_dir = Path('/content/drive/My Drive/Colab Notebooks/output/sub')\n","\n","train_file = data_dir / 'train.csv'\n","test_file = data_dir / 'test.csv'\n","sample_file = data_dir / 'sample_submission.csv'"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4AEkySZlf5Oh","executionInfo":{"status":"ok","timestamp":1601814495941,"user_tz":-540,"elapsed":1506,"user":{"displayName":"bare","photoUrl":"","userId":"10819893525008163668"}}},"source":["algorithm_name = 'lgbmcv'\n","feature_name = 'stacking1'\n","model_name = f'{algorithm_name}_{feature_name}_4'\n","\n","feature_Ver1_file = feature_dir / f'{feature_name}_Ver1.csv'\n","feature_Ver2_file = feature_dir / f'{feature_name}_Ver2.csv'\n","feature_target_file = feature_dir / f'feature_target.csv'\n","\n","stacking1_oof_pred_file = val_dir / f'{model_name}_oof_pred.csv'\n","stacking1_test_pred_file = test_dir / f'{model_name}_test_pred.csv'\n","stacking1_submission_file = sub_dir / f'{model_name}_submission.csv'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"yoicve7vkg1a","executionInfo":{"status":"ok","timestamp":1601814496419,"user_tz":-540,"elapsed":1975,"user":{"displayName":"bare","photoUrl":"","userId":"10819893525008163668"}}},"source":["SEED = 2020\n","num_class = 3\n","n_splits = 5\n","target_column = 'class'"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XHnKJW3of5QS"},"source":["# Stacking Feature 생성"]},{"cell_type":"code","metadata":{"id":"JOMEtgXN9mXk","executionInfo":{"status":"ok","timestamp":1601814496419,"user_tz":-540,"elapsed":1966,"user":{"displayName":"bare","photoUrl":"","userId":"10819893525008163668"}}},"source":["def load_data(model_names, oof_list, test_list, feature_names=None,number_of_versions=None):\n","    if number_of_versions == None or number_of_versions == 1:\n","        for model in model_names:\n","            oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver1.csv',delimiter=','))\n","            test_list.append(np.loadtxt(test_dir / f'{model}_test_pred_ver1.csv', delimiter=','))\n","            if feature_names != None:\n","                feature_names += [f'{model}_ver1_class0', f'{model}_ver1_class1', f'{model}_ver1_class2']\n","    elif number_of_versions == 2:\n","        for model in model_names:\n","            oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver1.csv',delimiter=','))\n","            oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver2.csv', delimiter=','))\n","            test_list.append(np.loadtxt(test_dir / f'{model}_test_pred_ver1.csv',delimiter=','))\n","            test_list.append(np.loadtxt(test_dir / f'{model}_test_pred_ver2.csv', delimiter=','))\n","            if feature_names != None:\n","                feature_names += [f'{model}_ver1_class0', f'{model}_ver1_class1', f'{model}_ver1_class2',\n","                                  f'{model}_ver2_class0',f'{model}_ver2_class1',f'{model}_ver2_class2']\n","    elif number_of_versions == 2.1:\n","        for model in model_names:\n","            oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver1.csv',delimiter=','))\n","            oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver3.csv', delimiter=','))\n","            test_list.append(np.loadtxt(test_dir / f'{model}_test_pred_ver1.csv',delimiter=','))\n","            test_list.append(np.loadtxt(test_dir / f'{model}_test_pred_ver3.csv', delimiter=','))\n","            if feature_names != None:\n","                feature_names += [f'{model}_ver1_class0', f'{model}_ver1_class1', f'{model}_ver1_class2',\n","                                  f'{model}_ver3_class0',f'{model}_ver3_class1',f'{model}_ver3_class2']\n","    elif number_of_versions == 3:\n","        for model in model_names:\n","            oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver1.csv',delimiter=','))\n","            oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver2.csv', delimiter=','))\n","            oof_list.append(np.loadtxt(val_dir / f'{model}_oof_pred_ver3.csv', delimiter=','))\n","            test_list.append(np.loadtxt(test_dir / f'{model}_test_pred_ver1.csv',delimiter=','))\n","            test_list.append(np.loadtxt(test_dir / f'{model}_test_pred_ver2.csv', delimiter=','))\n","            test_list.append(np.loadtxt(test_dir / f'{model}_test_pred_ver3.csv', delimiter=','))\n","            if feature_names != None:\n","                feature_names += [f'{model}_ver1_class0', f'{model}_ver1_class1', f'{model}_ver1_class2',\n","                                  f'{model}_ver2_class0',f'{model}_ver2_class1', f'{model}_ver2_class2',\n","                                  f'{model}_ver3_class0', f'{model}_ver3_class1',f'{model}_ver3_class2']"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"_pZTd76wf5Sd","executionInfo":{"status":"ok","timestamp":1601814634529,"user_tz":-540,"elapsed":140066,"user":{"displayName":"bare","photoUrl":"","userId":"10819893525008163668"}}},"source":["all_oof = []\n","all_test = []\n","feature_names = []\n","\n","model_names = ['lrcv_feature', 'etscv_feature', 'rfcv_feature', 'gbcv_feature','xgbcv_feature','lgbmcv_feature','adacv_feature_2','adacv_feature']\n","load_data(model_names, all_oof, all_test, feature_names,3)\n","\n","model_names = ['lrcv_polynomial_feature','rfcv_polynomial_feature','etscv_polynomial_feature','gbcv_polynomial_feature','adacv_polynomial_feature_2','adacv_polynomial_feature']\n","load_data(model_names,all_oof, all_test,feature_names,3)\n","\n","model_names = ['xgbcv_polynomial_feature','lgbmcv_polynomial_feature']\n","load_data(model_names,all_oof, all_test,feature_names,2.1)\n","\n","all_oof = np.column_stack(all_oof)\n","all_test = np.column_stack(all_test)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZwCyrN0jjuxp","executionInfo":{"status":"ok","timestamp":1601814634535,"user_tz":-540,"elapsed":140063,"user":{"displayName":"bare","photoUrl":"","userId":"10819893525008163668"}},"outputId":"7942142c-6b24-4cb5-96c3-248a269f02cd","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y = pd.read_csv(feature_target_file, index_col=0, usecols=['id',target_column]).values.flatten()\n","y.shape"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(319923,)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"y9j967_akXWH"},"source":["# Stacking\n","\n","- 각 oof마다 fold별로 logloos의 변동이 있으므로 최대한 정보를 뽑아내고자 스태킹을 함."]},{"cell_type":"code","metadata":{"id":"JLj3T0Y6k8gI","executionInfo":{"status":"ok","timestamp":1601814634536,"user_tz":-540,"elapsed":140055,"user":{"displayName":"bare","photoUrl":"","userId":"10819893525008163668"}}},"source":["# light gbm \n","lgbm_params = {\n","    'num_threads': -1, # aliases: n_jobs\n","    'num_iterations': 100, # aliases: n_estimators\n","    'metric': 'multi_logloss',\n","    'learning_rate': 0.3, # aliases: eta\n","    'boosting': 'gbdt', # aliases: boosting_type\n","    'objective': 'multiclass', # aliases: softmax\n","    'num_class': 3,\n","    'random_state': SEED,\n","    'device_type': 'gpu', # aliases: device\n","    'gpu_use_dp': 'true',\n","    'verbosity': 0, # aliases: verbose\n","}"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"67Gcb9twk0tq","outputId":"0ae34237-d323-47ea-8ea5-e1b728f65eeb","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["mlogloss = []\n","\n","stk_oof_pred = np.zeros((all_oof.shape[0],num_class))\n","stk_test_pred = np.zeros((all_test.shape[0],num_class))\n","\n","kFold = StratifiedKFold(n_splits=n_splits, random_state=2020, shuffle=True)\n","for fold, (trn_idx, val_idx) in enumerate(kFold.split(all_oof,y)):\n","    X_train, X_val = all_oof[trn_idx], all_oof[val_idx]\n","    y_train, y_val = y[trn_idx], y[val_idx]\n","\n","    dtrain = lgbm.Dataset(X_train, label=y_train)\n","    dval = lgbm.Dataset(X_val, label=y_val)\n","\n","    lgbm_clf = lgbm.train(params=lgbm_params, train_set=dtrain, num_boost_round=5000,valid_sets=[dtrain,dval], early_stopping_rounds=50, verbose_eval=5000)\n","    mlogloss.append(lgbm_clf.best_score['valid_1']['multi_logloss'])\n","\n","    stk_test_pred += lgbm_clf.predict(all_test) / n_splits\n","    stk_oof_pred[val_idx] = lgbm_clf.predict(X_val)\n","\n","print('mean logloss= ', np.mean(mlogloss))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds\n","Early stopping, best iteration is:\n","[15]\ttraining's multi_logloss: 0.143701\tvalid_1's multi_logloss: 0.155226\n","Training until validation scores don't improve for 50 rounds\n","Early stopping, best iteration is:\n","[15]\ttraining's multi_logloss: 0.144405\tvalid_1's multi_logloss: 0.154299\n","Training until validation scores don't improve for 50 rounds\n","Early stopping, best iteration is:\n","[17]\ttraining's multi_logloss: 0.141697\tvalid_1's multi_logloss: 0.153683\n","Training until validation scores don't improve for 50 rounds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NVhFNzi3YBz7"},"source":["# submission 파일 생성\n","\n","sub = pd.read_csv(sample_file)\n","sub[target_column] = np.argmax(stk_test_pred, axis=1)\n","sub.to_csv(stacking1_submission_file, index=False, encoding='utf-8-sig')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJtUbaj_YB_C"},"source":["# stcking1_oof_pred 파일 생성\n","\n","np.savetxt(stacking1_oof_pred_file, stk_oof_pred, fmt='%.18f',delimiter=',')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gvj2ftQuYCHq"},"source":["# stacking1_test_pred 파일 생성\n","\n","np.savetxt(stacking1_test_pred_file, stk_test_pred, fmt='%.18f', delimiter=',')"],"execution_count":null,"outputs":[]}]}